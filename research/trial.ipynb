{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178a2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f70e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f2c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f19719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhishek\\Desktop\\langgraph_learning\\langgraph_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4c11d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I help you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello!\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7811452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict\n",
    "\n",
    "#Reason of creating this state is that we will let this value goes through all node and get updated.\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents th state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        md_text: contains HR Reimbursement Policy\n",
    "        employee_invoice_data: contains employee invoice data\n",
    "    \"\"\"\n",
    "\n",
    "    md_text: str\n",
    "    employee_invoice_data: Dict[str, Dict[str, str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f472017",
   "metadata": {},
   "source": [
    "### Extracting HR Reimbursement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b868cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def extract_hr_policy_from_pdf(state: State, pdf_path: str) -> State:\n",
    "    \"\"\"\n",
    "    Extract HR reimbursement policy from PDF.\n",
    "    \n",
    "    Args:\n",
    "        state: LangGraph state to update\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with md_text containing extracted policy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #First I will try to extract directly from pdf if not able to do then will use vision model in our case GEMINI\n",
    "        md_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "        \n",
    "        # If no text extracted, convert PDF to images and feed to gemini\n",
    "        if not md_text or md_text.strip() == \"\":\n",
    "            \n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            all_extracted_text = []\n",
    "            \n",
    "            for page_num in range(len(pdf_document)):\n",
    "                # Convert page to PNG image\n",
    "                page = pdf_document[page_num]\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for clarity\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "                \n",
    "                # Convert to base64 as mentioned in Langchain-google-genai documentation: https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n",
    "                img_base64 = base64.b64encode(img_data).decode()\n",
    "                \n",
    "                # Create message with image and prompt\n",
    "                message = HumanMessage(\n",
    "                    content=[\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Extract the HR Reimbursement policy from this image. Return the text in markdown format.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                # Get extracted text from vision model\n",
    "                response = llm.invoke([message])\n",
    "                all_extracted_text.append(response.content)\n",
    "            \n",
    "            pdf_document.close()\n",
    "            \n",
    "            # Combine all page texts\n",
    "            md_text = \"\\n\\n\".join(all_extracted_text)\n",
    "        \n",
    "        # Update state with extracted text\n",
    "        state[\"md_text\"] = md_text\n",
    "        # print(md_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        state[\"md_text\"] = \"\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b55dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md_text': \"# **Company Name: IAI Solution** **Policy Title: Employee Reimbursement Policy** **Version: 1.0**\\n\\n**1. Purpose**\\n\\nThe purpose of this policy is to outline the guidelines and procedures for the reimbursement of\\nexpenses incurred by employees while performing work-related duties. This policy ensures\\ntransparency and consistency in the reimbursement process.\\n\\n\\n**2. Scope**\\n\\nThis policy applies to all employees of IAI Solution who incur expenses in the course of their\\nwork duties.\\n\\n\\n**3. Reimbursement Categories**\\n\\nThe following categories of expenses are eligible for reimbursement under this policy:\\n\\n\\n   - **Food and Beverages**\\n\\n   - **Travel Expenses**\\n\\n   - **Accommodations**\\n\\n**4. General Guidelines**\\n\\n\\n   - All reimbursements must be supported by original receipts and submitted within **30 days**\\nof the expense incurred.\\n\\n   - Employees must complete the reimbursement request form and submit it along with the\\nrequired documentation to the HR department.\\n\\n\\n**5. Specific Expense Guidelines**\\n\\n**5.1 Food and Beverages**\\n\\n\\n   - **Eligibility** : Reimbursement for meals is allowed when traveling for work or attending\\nbusiness meetings.\\n\\n   - **Limits** : We have set food allowances for food reimbursements of ‚Çπ200 per meal.\\n\\n   - **Restrictions** : Alcoholic beverages are not reimbursable.\\n\\n**5.2 Travel Expenses**\\n\\n\\n   - **Eligibility** : Travel expenses are reimbursable for work-related travel only.\\n\\n\\n       - **Limits** : We have set allowances for travel reimbursements of ‚Çπ2,000 per trip, depending\\non the location and the employee's level. The allowance for daily office cabs is ‚Çπ150.\\n\\n       - **Restrictions** : Any travel-related expenses incurred for personal reasons will not be\\n\\nreimbursed.\\n\\n\\n**5.3 Accommodation**\\n\\n\\n       - **Eligibility** : Reimbursement for hotel stays is allowed for overnight business travel.\\n\\n       - **Limits** : Up to ‚Çπ50 per night, excluding taxes and fees.\\n\\n       - **Restrictions** : Employees must use company-approved hotels when available.\\n\\n**6. Submission Process**\\n\\n\\n1. Complete the reimbursement request form.\\n2. Attach all relevant receipts.\\n3. Submit to the HR department for approval.\\n\\n**7. Review and Approval**\\n\\nHR will review submissions for compliance with this policy and will either approve or deny the\\n\\nrequest within 10 business days.\\n\\n\\n**8. Policy Amendments**\\n\\nThis policy may be amended at any time with prior notice to employees.\\n\\n\\n\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state = State(md_text=\"\")\n",
    "\n",
    "extract_hr_policy_from_pdf(current_state, \"C:/Users/Abhishek/Downloads/task-1-dataset/HR_Policy.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e38756",
   "metadata": {},
   "source": [
    "### Extracting \n",
    "ZIP file containing one or more employee invoice PDFs.\n",
    "Employee Name: To link the invoice analysis to a specific employee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f78ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_invoices(state, zip_path):\n",
    "    \"\"\"Main function: Extract ZIP ‚Üí Process PDFs ‚Üí Store in state\"\"\"\n",
    "\n",
    "    # Initialize state\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        state[\"employee_invoice_data\"] = {}\n",
    "\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            # Step 1: Extract ZIP and find all PDFs\n",
    "            pdf_files = extract_zip_and_find_pdfs(zip_path, temp_dir)\n",
    "            print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "            # Step 2: Process each PDF\n",
    "            for pdf_path in pdf_files:\n",
    "                invoice_data = extract_invoice_data(pdf_path, state)\n",
    "\n",
    "                if invoice_data:\n",
    "                    employee_name = get_employee_name(invoice_data)\n",
    "\n",
    "                    # Step 3: Store in state\n",
    "                    if employee_name in state[\"employee_invoice_data\"]:\n",
    "                        state[\"employee_invoice_data\"][employee_name] += \"\\n\\n---\\n\\n\" + invoice_data\n",
    "                    else:\n",
    "                        state[\"employee_invoice_data\"][employee_name] = invoice_data\n",
    "\n",
    "            print(f\"Processed {len(state['employee_invoice_data'])} employees\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        state[\"employee_invoice_data\"][\"Error\"] = str(e)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4a1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_and_find_pdfs(zip_path, extract_to):\n",
    "    \"\"\"Extract ZIP file and return list of PDF file paths\"\"\"\n",
    "    pdf_files = []\n",
    "    \n",
    "    # Extract ZIP\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    # Find all PDFs (including nested ZIPs)\n",
    "    for root, dirs, files in os.walk(extract_to):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            if file.lower().endswith('.pdf'):\n",
    "                pdf_files.append(file_path)\n",
    "            \n",
    "            elif file.lower().endswith('.zip'):\n",
    "                # Handle nested ZIP\n",
    "                nested_dir = os.path.join(root, f\"nested_{file[:-4]}\")\n",
    "                os.makedirs(nested_dir, exist_ok=True)\n",
    "                nested_pdfs = extract_zip_and_find_pdfs(file_path, nested_dir)\n",
    "                pdf_files.extend(nested_pdfs)\n",
    "    \n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95cc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_invoice_data(pdf_path, state):\n",
    "    \"\"\"Extract invoice data from PDF using text extraction or vision model\"\"\"\n",
    "    try:\n",
    "        # Try text extraction first\n",
    "        text = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "        if not text or text.strip() == \"\":\n",
    "            # Use vision model if text extraction fails\n",
    "            text = extract_with_vision(pdf_path, state)\n",
    "        else:\n",
    "            # Process extracted text with LLM\n",
    "            text = process_with_llm(text, state)\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a9181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_vision(pdf_path, state):\n",
    "    \"\"\"Use vision model to extract data from PDF images\"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_text = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "        img_data = pix.tobytes(\"png\")\n",
    "        img_base64 = base64.b64encode(img_data).decode()\n",
    "\n",
    "        # Get the image content first, then process with full prompt\n",
    "        message = HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": \"Extract all text and details from this invoice image:\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "        ])\n",
    "\n",
    "        response = llm.invoke([message])\n",
    "        extracted_text = response.content\n",
    "        \n",
    "        # Now process with full prompt including status prediction\n",
    "        full_prompt = get_extraction_prompt(state)\n",
    "        final_message = HumanMessage(content=f\"{full_prompt}\\n\\nExtracted text:\\n\\n{extracted_text}\")\n",
    "        final_response = llm.invoke([final_message])\n",
    "        \n",
    "        all_text.append(final_response.content)\n",
    "\n",
    "    doc.close()\n",
    "    return \"\\n\\n\".join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "589ad563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_llm(text, state):\n",
    "    \"\"\"Process text-extracted content with LLM for better structure\"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "    prompt = get_extraction_prompt(state)\n",
    "    \n",
    "    message = HumanMessage(content=f\"{prompt}\\n\\nExtracted text:\\n\\n{text}\")\n",
    "    response = llm.invoke([message])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "def get_extraction_prompt(State):\n",
    "    \"\"\"Standard prompt for invoice data extraction\"\"\"\n",
    "    md_text = State.get(\"md_text\", \"\")\n",
    "    return f\"\"\"Extract invoice information and identify the EMPLOYEE NAME.\n",
    "\n",
    "EMPLOYEE NAME RULES:\n",
    "- For MEAL invoices: Look for \"Customer Name\"\n",
    "- For TRAVEL invoices: Look for \"Passenger Details\" \n",
    "- For CAB invoices: Look for \"Customer Name\"\n",
    "- If no customer/passenger name found: use \"No information about employee\"\n",
    "\n",
    "REIMBURSEMENT STATUS ANALYSIS:\n",
    "Based on the HR reimbursement policy below, analyze the invoice and determine status:\n",
    "\n",
    "**HR REIMBURSEMENT POLICY:**\n",
    "{md_text}\n",
    "\n",
    "**Reimbursement Status Categories:**\n",
    "- **Fully Reimbursed:** The entire invoice amount is reimbursable according to the HR policy\n",
    "- **Partially Reimbursed:** Only a portion of the invoice amount is reimbursable according to the HR policy\n",
    "- **Declined:** The invoice is not reimbursable according to the HR policy\n",
    "\n",
    "FORMAT:\n",
    "**EMPLOYEE NAME:** [exact name or \"No information about employee\"]\n",
    "\n",
    "**REIMBURSEMENT STATUS:** [**Fully Reimbursed** OR **Partially Reimbursed** OR **Declined**]\n",
    "\n",
    "**INVOICE DETAILS:**\n",
    "- Invoice Type: [Meal/Travel/Cab/Accomodation/Other]\n",
    "- Invoice Number: [if available]\n",
    "- Date: [date]\n",
    "- Total Amount: [amount with currency]\n",
    "- Description: [brief description]\n",
    "- Reason: What is the reason for this reimbursement?\n",
    "\n",
    "Return clean markdown format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff972178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_employee_name(invoice_text):\n",
    "    \"\"\"Extract employee name from processed invoice text\"\"\"\n",
    "    try:\n",
    "        lines = invoice_text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if '**EMPLOYEE NAME:**' in line:\n",
    "                name = line.split(':', 1)[1].strip()\n",
    "                name = name.replace('**', '').replace('*', '').strip()\n",
    "                \n",
    "                if name and name != \"No information about employee\":\n",
    "                    return name\n",
    "        \n",
    "        # Fallback: search for customer patterns\n",
    "        patterns = [\n",
    "            r'Customer Name[:\\s]+([A-Za-z\\s]+)',\n",
    "            r'Passenger[:\\s]+([A-Za-z\\s]+)',\n",
    "            r'Name[:\\s]+([A-Za-z\\s]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, invoice_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                name = matches[0].strip()\n",
    "                if name and len(name) > 1:\n",
    "                    return name\n",
    "        \n",
    "        return \"No information about employee\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing employee name: {e}\")\n",
    "        return \"No information about employee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b60fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_employee_invoices(state, employee_name):\n",
    "    \"\"\"Get all invoices for a specific employee\"\"\"\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        return \"No invoice data available\"\n",
    "    \n",
    "    # Exact match\n",
    "    if employee_name in state[\"employee_invoice_data\"]:\n",
    "        return state[\"employee_invoice_data\"][employee_name]\n",
    "    \n",
    "    # Fuzzy match\n",
    "    for emp_name in state[\"employee_invoice_data\"].keys():\n",
    "        if employee_name.lower() in emp_name.lower() or emp_name.lower() in employee_name.lower():\n",
    "            return state[\"employee_invoice_data\"][emp_name]\n",
    "    \n",
    "    return f\"No invoices found for {employee_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36073b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(state):\n",
    "    \"\"\"Get summary of all employees and their invoices with category and description\"\"\"\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        return {}\n",
    "    \n",
    "    summary = {}\n",
    "    for employee_name, invoice_data in state[\"employee_invoice_data\"].items():\n",
    "        invoice_count = invoice_data.count(\"**INVOICE DETAILS:**\")\n",
    "        amounts = re.findall(r'Total Amount[:\\s]+[‚Çπ$]\\s*([0-9,]+\\.?\\d*)', invoice_data)\n",
    "        total_amount = sum(float(amt.replace(',', '')) for amt in amounts if amt)\n",
    "        \n",
    "        # Get invoice category and description\n",
    "        category, description = get_invoice_category_and_description(invoice_data)\n",
    "        status = get_reimbursement_status(invoice_data)\n",
    "        summary[employee_name] = {\n",
    "            'invoice_count': invoice_count,\n",
    "            'invoice_mode': category,\n",
    "            'Reimbursement_Status': status,\n",
    "            'description': description\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6928e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invoice_category_and_description(invoice_data):\n",
    "    \"\"\"Extract invoice category and generate detailed description\"\"\"\n",
    "    try:\n",
    "        # Get category from invoice type\n",
    "        category_match = re.search(r'Invoice Type[:\\s]+([A-Za-z/]+)', invoice_data, re.IGNORECASE)\n",
    "        category = category_match.group(1).lower() if category_match else \"other\"\n",
    "        \n",
    "        # Normalize category\n",
    "        if 'meal' in category or 'food' in category:\n",
    "            category = 'meal'\n",
    "        elif 'travel' in category or 'ticket' in category or 'flight' in category or 'train' in category:\n",
    "            category = 'travel'\n",
    "        elif 'cab' in category or 'taxi' in category or 'uber' in category or 'ola' in category:\n",
    "            category = 'cab'\n",
    "        elif 'hotel' in category or 'house' in category or 'pg' in category or 'hostel' in category:\n",
    "            category = 'accomodation'\n",
    "        else:\n",
    "            category = 'other'\n",
    "        \n",
    "        # Generate description using LLM\n",
    "        description = generate_description_with_llm(invoice_data, category)\n",
    "        \n",
    "        return category, description\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting category: {e}\")\n",
    "        return \"other\", \"Unable to generate description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39df4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description_with_llm(invoice_data, category):\n",
    "    \"\"\"Use LLM to generate category-specific description\"\"\"\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "        \n",
    "        if category == 'travel':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT travel description (max 2 lines):\n",
    "            \n",
    "Include: Mode of travel, total cost, from which location to where, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"Flight from Delhi to Mumbai, total cost ‚Çπ5,000, Date is 12/02/22, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ‚Çπ2000 as per 5.2 Travel Expenses \" or \"Train journey from Chennai to Bangalore, total cost ‚Çπ800, Date is 12/3/23, since it is within limit as mentioned in HR Reimbursement Policy hence it is fully reimburse as per 5.2 Travel Expenses .\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'meal':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT meal description (max 2 lines):\n",
    "            \n",
    "Include: Cuisine/food name, total cost, restaurant name, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"North Indian cuisine at Punjabi Dhaba, total cost ‚Çπ450, Date is 4/2/25, within HR Policy Budget as per 5.1 Food and Beverages.\" or \"Pizza and beverages at Domino's, total cost ‚Çπ600, Date is 23/5/24, it's not with HR Reimbursement policy as given budget by HR is ‚Çπ500 but your total cost is ‚Çπ600 hence it is partially reimburse as per 5.1 Food and Beverages .\"\n",
    "\n",
    "Include: If Cuisine/food include any wine/wodka/cigrate\n",
    "Format: \"Decline!!! as wine doesn't comes under reimbursement Policy as per 5.1 Food and Beverages.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'cab':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT cab description (max 2 lines):\n",
    "            \n",
    "Include: Total cost, pickup and drop location if available, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"Cab ride from Airport to Hotel, total cost ‚Çπ350, Date of travel is 23/2/21, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse\" or \"Uber ride within city, total cost ‚Çπ120, Date of travel is 3/01/2002, its within the limit as per 5.2 Travel Expenses hence fully reimburse.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'accomodation':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT cab description (max 2 lines):\n",
    "            \n",
    "Include: Total cost, hotel name if available, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"You stayed in hotel for 2 days, total cost ‚Çπ350, Date of travel is 23/2/21, it's more than HR Reimbursement Policy as per 5.3 Accommodation hence partially reimburse\" or \"You stayed in PG, total cost ‚Çπ120, Date of travel is 3/01/2002, its within the limit as per 5.3 Accommodation hence fully reimburse.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT description (max 2 lines):\n",
    "            \n",
    "Include: Service type, total cost,Date (should stricly match DD/MM/YYYY format), brief details\n",
    "Format: \"Service description with cost\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        \n",
    "        message = HumanMessage(content=prompt + invoice_data)\n",
    "        response = llm.invoke([message])\n",
    "        \n",
    "        # Clean up the response\n",
    "        description = response.content.strip()\n",
    "        # Remove quotes if present\n",
    "        if description.startswith('\"') and description.endswith('\"'):\n",
    "            description = description[1:-1]\n",
    "        \n",
    "        return description\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description: {e}\")\n",
    "        return f\"Invoice total with basic details (Error: {str(e)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f569b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reimbursement_status(invoice_text):\n",
    "    \"\"\"Extract reimbursement status from processed invoice text\"\"\"\n",
    "    try:\n",
    "        lines = invoice_text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if '**REIMBURSEMENT STATUS:**' in line:\n",
    "                status = line.split(':', 1)[1].strip()\n",
    "                status = status.replace('**', '').replace('*', '').strip()\n",
    "                \n",
    "                if status:\n",
    "                    return status\n",
    "        \n",
    "        # Fallback: search for status patterns\n",
    "        patterns = [\n",
    "            r'Status[:\\s]+([A-Za-z\\s*]+)',\n",
    "            r'Reimbursement[:\\s]+([A-Za-z\\s*]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, invoice_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                status = matches[0].strip()\n",
    "                if status and len(status) > 1:\n",
    "                    return status\n",
    "        \n",
    "        return \"**Pending Review**\"  # Default status\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing reimbursement status: {e}\")\n",
    "        return \"**Pending Review**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09dd3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "import pymupdf4llm\n",
    "import fitz\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1ab045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HR POLICY EXTRACTION DEBUG ===\n",
      "HR Policy extracted: 2416 characters\n",
      "HR Policy preview: # **Company Name: IAI Solution** **Policy Title: Employee Reimbursement Policy** **Version: 1.0**\n",
      "\n",
      "**1. Purpose**\n",
      "\n",
      "The purpose of this policy is to outline the guidelines and procedures for the reimbu...\n",
      "==================================================\n",
      "Found 6 PDF files\n",
      "Processed 6 employees\n",
      "Summary with categories and descriptions:\n",
      "\n",
      "Rekha:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Seema:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ‚Çπ141, Date of travel is 19/09/2024, it's within the company's allowance limit of ‚Çπ150 hence fully reimburse.\n",
      "  Reimbursement Status: Fully Reimbursed\n",
      "\n",
      "Hardik:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: Indian cuisine at Restaurant name not specified, total cost ‚Çπ607.70, Date is 03/12/2024, it's not fully within HR Reimbursement policy as given budget by HR is ‚Çπ200 but your total cost is ‚Çπ607.70 hence it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Shivam M:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: South Indian Mini Meals and Chapati at Udapi Hotel, total cost ‚Çπ374.00, Date is 13/12/2024, meal reimbursement for work-related purposes, and it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Sushma:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Bangalore to Surat, total cost ‚Çπ7377, Date is 25/07/2024, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ‚Çπ2,000 per trip.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Rani:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Chennai to Surat, total cost ‚Çπ9899, Date is 25/07/2024, reason of partially reimbursement is that the total fare of ‚Çπ9899 exceeds the HR policy limit of ‚Çπ2,000 for travel reimbursements per trip, making only a portion eligible for reimbursement.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "==================================================\n",
      "=== STATE CONTENTS ===\n",
      "Available keys: ['md_text', 'employee_invoice_data', 'extract_invoice_data']\n",
      "\n",
      "=== extract_invoice_data ===\n",
      "Type: <class 'dict'>\n",
      "Number of employees: 6\n",
      "\n",
      "Rekha:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Seema:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ‚Çπ141, Date of travel is 19/09/2024, it's within the company's allowance limit of ‚Çπ150 hence fully reimburse.\n",
      "  Reimbursement Status: Fully Reimbursed\n",
      "\n",
      "Hardik:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: Indian cuisine at Restaurant name not specified, total cost ‚Çπ607.70, Date is 03/12/2024, it's not fully within HR Reimbursement policy as given budget by HR is ‚Çπ200 but your total cost is ‚Çπ607.70 hence it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Shivam M:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: South Indian Mini Meals and Chapati at Udapi Hotel, total cost ‚Çπ374.00, Date is 13/12/2024, meal reimbursement for work-related purposes, and it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Sushma:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Bangalore to Surat, total cost ‚Çπ7377, Date is 25/07/2024, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ‚Çπ2,000 per trip.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Rani:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Chennai to Surat, total cost ‚Çπ9899, Date is 25/07/2024, reason of partially reimbursement is that the total fare of ‚Çπ9899 exceeds the HR policy limit of ‚Çπ2,000 for travel reimbursements per trip, making only a portion eligible for reimbursement.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "=== employee_invoice_data (raw) ===\n",
      "Number of employees: 6\n",
      "- Rekha\n",
      "- Seema\n",
      "- Hardik\n",
      "- Shivam M\n",
      "- Sushma\n",
      "- Rani\n",
      "\n",
      "==================================================\n",
      "Sample employee data for 'Rekha':\n",
      "{'invoice_count': 1, 'invoice_mode': 'cab', 'Reimbursement_Status': 'Partially Reimbursed', 'description': \"Daily office cab ride, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\"}\n"
     ]
    }
   ],
   "source": [
    "# Modified example_usage function to accept state as parameter\n",
    "def example_usage(state):\n",
    "    \"\"\"Example of how to use the code - now accepts state as parameter\"\"\"\n",
    "\n",
    "    state = {\"md_text\": \"\", \"employee_invoice_data\": {}}\n",
    "    state = extract_hr_policy_from_pdf(state, \"C:/Users/Abhishek/Downloads/task-1-dataset/HR_Policy.pdf\")\n",
    "\n",
    "    # Debug: Check if HR policy was extracted\n",
    "    print(\"=== HR POLICY EXTRACTION DEBUG ===\")\n",
    "    print(f\"HR Policy extracted: {len(state.get('md_text', ''))} characters\")\n",
    "    if state.get('md_text'):\n",
    "        print(f\"HR Policy preview: {state['md_text'][:200]}...\")\n",
    "    else:\n",
    "        print(\"WARNING: No HR policy extracted!\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Step 1: Initialize state if needed (don't create new state)\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        state[\"employee_invoice_data\"] = {}\n",
    "\n",
    "    # Step 2: Process ZIP file\n",
    "    zip_path = \"C:/Users/Abhishek/Downloads/dataset.zip\"\n",
    "    state = process_invoices(state, zip_path)\n",
    "\n",
    "    # Step 3: Get results with category and description\n",
    "    summary = get_summary(state)\n",
    "    \n",
    "    # Step 4: Store summary in state[\"extract_invoice_data\"] (as you wanted)\n",
    "    state[\"extract_invoice_data\"] = summary\n",
    "    \n",
    "    print(\"Summary with categories and descriptions:\")\n",
    "    for employee, details in summary.items():\n",
    "        print(f\"\\n{employee}:\")\n",
    "        print(f\"  Invoice Count: {details['invoice_count']}\")\n",
    "        print(f\"  Invoice Mode: {details['invoice_mode']}\")\n",
    "        print(f\"  Description: {details['description']}\")\n",
    "        print(f\"  Reimbursement Status: {details['Reimbursement_Status']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "# Alternative: If you want to check what's stored\n",
    "def check_state_contents(state):\n",
    "    \"\"\"Helper function to check what's stored in state\"\"\"\n",
    "    print(\"=== STATE CONTENTS ===\")\n",
    "    print(f\"Available keys: {list(state.keys())}\")\n",
    "    \n",
    "    # Check extract_invoice_data\n",
    "    if \"extract_invoice_data\" in state:\n",
    "        print(f\"\\n=== extract_invoice_data ===\")\n",
    "        print(f\"Type: {type(state['extract_invoice_data'])}\")\n",
    "        print(f\"Number of employees: {len(state['extract_invoice_data'])}\")\n",
    "        \n",
    "        for employee, details in state[\"extract_invoice_data\"].items():\n",
    "            print(f\"\\n{employee}:\")\n",
    "            print(f\"  Invoice Count: {details['invoice_count']}\")\n",
    "            print(f\"  Invoice Mode: {details['invoice_mode']}\")\n",
    "            print(f\"  Description: {details['description']}\")\n",
    "            print(f\"  Reimbursement Status: {details['Reimbursement_Status']}\") \n",
    "    \n",
    "    # Check raw employee_invoice_data\n",
    "    if \"employee_invoice_data\" in state:\n",
    "        print(f\"\\n=== employee_invoice_data (raw) ===\")\n",
    "        print(f\"Number of employees: {len(state['employee_invoice_data'])}\")\n",
    "        for emp_name in state[\"employee_invoice_data\"].keys():\n",
    "            print(f\"- {emp_name}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    state = {}\n",
    "    \n",
    "    # Process invoices and get results\n",
    "    state = example_usage(state)\n",
    "    \n",
    "    # Optional: Check what's stored\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    check_state_contents(state)\n",
    "    \n",
    "    # Optional: Access specific employee data\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if \"extract_invoice_data\" in state:\n",
    "        employee_name = list(state[\"extract_invoice_data\"].keys())[0]  # Get first employee\n",
    "        print(f\"Sample employee data for '{employee_name}':\")\n",
    "        print(state[\"extract_invoice_data\"][employee_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4e528",
   "metadata": {},
   "source": [
    "### Let's store employee name and its detail in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c194467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from typing import Dict, List, Optional, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8077f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"employee-database\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063068c",
   "metadata": {},
   "source": [
    "Since we need to add date in meta data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1917b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_from_description(description: str) -> Optional[str]:\n",
    "    \"\"\"Extract date from description using regex.\"\"\"\n",
    "    if not description:\n",
    "        return None\n",
    "    \n",
    "    # Simple regex for DD/MM/YYYY format\n",
    "    date_pattern = r'\\b(\\d{1,2})/(\\d{1,2})/(\\d{4})\\b'\n",
    "    match = re.search(date_pattern, description)\n",
    "    \n",
    "    if match:\n",
    "        day, month, year = match.groups()\n",
    "        return f\"{day.zfill(2)}/{month.zfill(2)}/{year}\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194dd3e",
   "metadata": {},
   "source": [
    "Our main logic here to push employee 1 along with its all relavent detail as one chunk along with employee name and date as meta data and later on we will perform Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76e67f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_employees_to_pinecone(employee_invoice_data: Dict[str, Dict[str, str]]):\n",
    "    \"\"\"\n",
    "    Process employee data and add to Pinecone - Simple approach like your example.\n",
    "    \"\"\"\n",
    "    # Initialize embeddings and Pinecone\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Setup Pinecone index (create if not exists)\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    # Create index if it doesn't exist\n",
    "    existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "    if INDEX_NAME in existing_indexes:\n",
    "        print(f\"üóëÔ∏è  Deleting existing index: {INDEX_NAME}\")\n",
    "        pc.delete_index(INDEX_NAME)\n",
    "        \n",
    "        # Wait for deletion to complete (important!)\n",
    "        import time\n",
    "        print(\"‚è≥ Waiting for index deletion to complete...\")\n",
    "        while INDEX_NAME in [index.name for index in pc.list_indexes()]:\n",
    "            time.sleep(1)\n",
    "        print(\"‚úÖ Index deletion completed\")\n",
    "\n",
    "    \n",
    "    print(f\"üÜï Creating fresh index: {INDEX_NAME}\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    \n",
    "    # Wait for index to be ready\n",
    "    print(\"‚è≥ Waiting for index to be ready...\")\n",
    "    while not pc.Index(INDEX_NAME).describe_index_stats():\n",
    "        time.sleep(1)\n",
    "    print(\"‚úÖ Index is ready\")\n",
    "\n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Process each employee - similar to your page_info loop\n",
    "    all_chunks = []\n",
    "    \n",
    "    for employee_name, employee_data in employee_invoice_data.items():\n",
    "        # Create text content\n",
    "        text = f\"\"\"\n",
    "        Employee Name: {employee_name}\n",
    "        Invoice Count: {employee_data.get('invoice_count', 0)}\n",
    "        Invoice Mode: {employee_data.get('invoice_mode', 'N/A')}\n",
    "        Reimbursement Status: {employee_data.get('Reimbursement_Status', 'N/A')}\n",
    "        Description: {employee_data.get('description', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract date from description\n",
    "        extracted_date = extract_date_from_description(employee_data.get('description', ''))\n",
    "        \n",
    "        # Create document - similar to your Document creation\n",
    "        doc = Document(\n",
    "            page_content=text.strip(),\n",
    "            metadata={\n",
    "                \"employee_name\": employee_name,\n",
    "                \"date\": extracted_date,\n",
    "                \"document_type\": \"employee_record\",\n",
    "                \"text\": text.strip()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        all_chunks.append(doc)\n",
    "    \n",
    "    # Add all documents to Pinecone\n",
    "    vector_store.add_documents(all_chunks)\n",
    "    time.sleep(1)\n",
    "    print(f\"‚úÖ Successfully added {len(all_chunks)} employee records to Pinecone\")\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Pinecone Data Verification...\n",
      "\n",
      "==================================================\n",
      "STEP 1: Index Stats & Employee Search\n",
      "==================================================\n",
      "üìä Index Stats:\n",
      "   Total Vectors: 3\n",
      "   Dimension: 384\n",
      "   Index Fullness: 0.0\n",
      "\n",
      "üîç Searching for: Sarah\n",
      "‚úÖ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2105\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ‚Çπ8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Searching for: John\n",
      "‚úÖ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: John\n",
      "   Date: 18/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2822\n",
      "   Content:\n",
      "   Employee Name: John\n",
      "        Invoice Count: 2\n",
      "        Invoice Mode: food\n",
      "        Reimbursement Status: Fully Reimbursed\n",
      "        Description: Team lunch expense, total cost ‚Çπ450, Date of travel is 18/09/2024, within policy limits.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Searching for: Rekha\n",
      "‚úÖ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.1962\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Searching for: Mike\n",
      "‚ùå No results found\n",
      "\n",
      "==================================================\n",
      "STEP 2: All Documents in Index\n",
      "==================================================\n",
      "üîç ALL DOCUMENTS IN INDEX:\n",
      "‚úÖ Found 3 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: John\n",
      "   Date: 18/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.3031\n",
      "   Content:\n",
      "   Employee Name: John\n",
      "        Invoice Count: 2\n",
      "        Invoice Mode: food\n",
      "        Reimbursement Status: Fully Reimbursed\n",
      "        Description: Team lunch expense, total cost ‚Çπ450, Date of travel is 18/09/2024, within policy limits.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÑ RESULT 2:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2404\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ‚Çπ8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìÑ RESULT 3:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2255\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üë• Unique Employee Names Found: ['Sarah', 'John', 'Rekha']\n",
      "\n",
      "==================================================\n",
      "STEP 3: Specific Employee Searches\n",
      "==================================================\n",
      "üîç Testing with 'Rekha' (from your example):\n",
      "‚úÖ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.1962\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ‚Çπ167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üîç Testing with 'Sarah':\n",
      "‚úÖ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "üìÑ RESULT 1:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2105\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ‚Çπ8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def search_by_employee_name(employee_name: str, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Search for documents by employee name using metadata filtering\n",
    "    \n",
    "    Args:\n",
    "        employee_name: Name of employee to search for\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of documents with metadata\n",
    "    \"\"\"\n",
    "    # Initialize embeddings (same as used during indexing)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Create metadata filter for employee name\n",
    "    metadata_filter = {\"employee_name\": employee_name}\n",
    "    \n",
    "    # Perform search with metadata filter\n",
    "    # Using a generic query since we're mainly filtering by metadata\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query=\"employee record\",\n",
    "        k=top_k,\n",
    "        filter=metadata_filter\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_search_results(results):\n",
    "    \"\"\"\n",
    "    Print search results in a readable format\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"‚ùå No results found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(results)} results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\nüìÑ RESULT {i}:\")\n",
    "        print(f\"   Employee Name: {doc.metadata.get('employee_name', 'N/A')}\")\n",
    "        print(f\"   Date: {doc.metadata.get('date', 'N/A')}\")\n",
    "        print(f\"   Document Type: {doc.metadata.get('document_type', 'N/A')}\")\n",
    "        print(f\"   Similarity Score: {score:.4f}\")\n",
    "        print(f\"   Content:\")\n",
    "        print(f\"   {doc.page_content}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "def verify_pinecone_data():\n",
    "    \"\"\"\n",
    "    Verify what data is stored in Pinecone\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone client\n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        index = pc.Index(INDEX_NAME)\n",
    "        \n",
    "        # Get index stats\n",
    "        stats = index.describe_index_stats()\n",
    "        print(f\"üìä Index Stats:\")\n",
    "        print(f\"   Total Vectors: {stats.total_vector_count}\")\n",
    "        print(f\"   Dimension: {stats.dimension}\")\n",
    "        print(f\"   Index Fullness: {stats.index_fullness}\")\n",
    "        \n",
    "        # Test with different employee names\n",
    "        test_employees = [\"Sarah\", \"John\", \"Rekha\", \"Mike\"]\n",
    "        \n",
    "        for employee in test_employees:\n",
    "            print(f\"\\nüîç Searching for: {employee}\")\n",
    "            results = search_by_employee_name(employee)\n",
    "            print_search_results(results)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "\n",
    "def search_all_employees():\n",
    "    \"\"\"\n",
    "    Get all documents without any filter to see what's in the index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize embeddings and vector store\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        vector_store = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        \n",
    "        # Search without any filter to get all documents\n",
    "        results = vector_store.similarity_search_with_score(\n",
    "            query=\"employee\",\n",
    "            k=20  # Get more results to see all employees\n",
    "        )\n",
    "        \n",
    "        print(f\"üîç ALL DOCUMENTS IN INDEX:\")\n",
    "        print_search_results(results)\n",
    "        \n",
    "        # Extract unique employee names\n",
    "        employee_names = set()\n",
    "        for doc, score in results:\n",
    "            name = doc.metadata.get('employee_name')\n",
    "            if name:\n",
    "                employee_names.add(name)\n",
    "        \n",
    "        print(f\"\\nüë• Unique Employee Names Found: {list(employee_names)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error searching all employees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be715eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "def answer_query_for_employee(employee_name: str, query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Answer a user query for a specific employee using Pinecone context and Gemini LLM.\n",
    "\n",
    "    Args:\n",
    "        employee_name: The name of the employee to search for\n",
    "        query: The user's question (e.g. reimbursement status)\n",
    "        top_k: Number of Pinecone results to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Answer string from Gemini\n",
    "    \"\"\"\n",
    "    # Step 1: Get relevant documents for the employee\n",
    "    results = search_by_employee_name(employee_name, top_k=top_k)\n",
    "\n",
    "    if not results:\n",
    "        return f\"‚ùå No data found for employee: {employee_name}\"\n",
    "\n",
    "    # Step 2: Concatenate all context from Pinecone\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "\n",
    "    # Step 3: Define a prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are an HR assistant AI. Use the following employee information to answer the user's question.\n",
    "\n",
    "Employee Data:\n",
    "------------------\n",
    "{context}\n",
    "\n",
    "User Question:\n",
    "------------------\n",
    "{question}\n",
    "\n",
    "Give a concise, helpful, and context-grounded answer.\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    # Step 4: Create LLM Chain\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    # Step 5: Run the chain\n",
    "    response = chain.run({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9651c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "John has 2 food-related expenses, totaling ‚Çπ450 for a team lunch on 18/09/2024. These expenses have been fully reimbursed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    emp_name = \"John\"\n",
    "    user_query = \"What are his expenses?\"\n",
    "\n",
    "    answer = answer_query_for_employee(emp_name, user_query)\n",
    "    print(f\"\\nü§ñ Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2285f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Answer:\n",
      "Your cab ride cost ‚Çπ167, which is more than the amount allowed by the company's reimbursement policy. Therefore, you were partially reimbursed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    emp_name = \"Rekha\"\n",
    "    user_query = \"Why I had been partially reimbersued?\"\n",
    "\n",
    "    answer = answer_query_for_employee(emp_name, user_query)\n",
    "    print(f\"\\nü§ñ Answer:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
