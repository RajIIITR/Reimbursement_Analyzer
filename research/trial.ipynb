{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178a2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f70e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f2c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f19719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhishek\\Desktop\\langgraph_learning\\langgraph_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4c11d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I help you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello!\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7811452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict\n",
    "\n",
    "#Reason of creating this state is that we will let this value goes through all node and get updated.\n",
    "class State(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents th state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        md_text: contains HR Reimbursement Policy\n",
    "        employee_invoice_data: contains employee invoice data\n",
    "    \"\"\"\n",
    "\n",
    "    md_text: str\n",
    "    employee_invoice_data: Dict[str, Dict[str, str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f472017",
   "metadata": {},
   "source": [
    "### Extracting HR Reimbursement Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b868cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def extract_hr_policy_from_pdf(state: State, pdf_path: str) -> State:\n",
    "    \"\"\"\n",
    "    Extract HR reimbursement policy from PDF.\n",
    "    \n",
    "    Args:\n",
    "        state: LangGraph state to update\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Updated state with md_text containing extracted policy\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #First I will try to extract directly from pdf if not able to do then will use vision model in our case GEMINI\n",
    "        md_text = pymupdf4llm.to_markdown(pdf_path)\n",
    "        \n",
    "        # If no text extracted, convert PDF to images and feed to gemini\n",
    "        if not md_text or md_text.strip() == \"\":\n",
    "            \n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            all_extracted_text = []\n",
    "            \n",
    "            for page_num in range(len(pdf_document)):\n",
    "                # Convert page to PNG image\n",
    "                page = pdf_document[page_num]\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for clarity\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "                \n",
    "                # Convert to base64 as mentioned in Langchain-google-genai documentation: https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n",
    "                img_base64 = base64.b64encode(img_data).decode()\n",
    "                \n",
    "                # Create message with image and prompt\n",
    "                message = HumanMessage(\n",
    "                    content=[\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Extract the HR Reimbursement policy from this image. Return the text in markdown format.\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{img_base64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                # Get extracted text from vision model\n",
    "                response = llm.invoke([message])\n",
    "                all_extracted_text.append(response.content)\n",
    "            \n",
    "            pdf_document.close()\n",
    "            \n",
    "            # Combine all page texts\n",
    "            md_text = \"\\n\\n\".join(all_extracted_text)\n",
    "        \n",
    "        # Update state with extracted text\n",
    "        state[\"md_text\"] = md_text\n",
    "        # print(md_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        state[\"md_text\"] = \"\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b55dc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'md_text': \"# **Company Name: IAI Solution** **Policy Title: Employee Reimbursement Policy** **Version: 1.0**\\n\\n**1. Purpose**\\n\\nThe purpose of this policy is to outline the guidelines and procedures for the reimbursement of\\nexpenses incurred by employees while performing work-related duties. This policy ensures\\ntransparency and consistency in the reimbursement process.\\n\\n\\n**2. Scope**\\n\\nThis policy applies to all employees of IAI Solution who incur expenses in the course of their\\nwork duties.\\n\\n\\n**3. Reimbursement Categories**\\n\\nThe following categories of expenses are eligible for reimbursement under this policy:\\n\\n\\n   - **Food and Beverages**\\n\\n   - **Travel Expenses**\\n\\n   - **Accommodations**\\n\\n**4. General Guidelines**\\n\\n\\n   - All reimbursements must be supported by original receipts and submitted within **30 days**\\nof the expense incurred.\\n\\n   - Employees must complete the reimbursement request form and submit it along with the\\nrequired documentation to the HR department.\\n\\n\\n**5. Specific Expense Guidelines**\\n\\n**5.1 Food and Beverages**\\n\\n\\n   - **Eligibility** : Reimbursement for meals is allowed when traveling for work or attending\\nbusiness meetings.\\n\\n   - **Limits** : We have set food allowances for food reimbursements of ₹200 per meal.\\n\\n   - **Restrictions** : Alcoholic beverages are not reimbursable.\\n\\n**5.2 Travel Expenses**\\n\\n\\n   - **Eligibility** : Travel expenses are reimbursable for work-related travel only.\\n\\n\\n       - **Limits** : We have set allowances for travel reimbursements of ₹2,000 per trip, depending\\non the location and the employee's level. The allowance for daily office cabs is ₹150.\\n\\n       - **Restrictions** : Any travel-related expenses incurred for personal reasons will not be\\n\\nreimbursed.\\n\\n\\n**5.3 Accommodation**\\n\\n\\n       - **Eligibility** : Reimbursement for hotel stays is allowed for overnight business travel.\\n\\n       - **Limits** : Up to ₹50 per night, excluding taxes and fees.\\n\\n       - **Restrictions** : Employees must use company-approved hotels when available.\\n\\n**6. Submission Process**\\n\\n\\n1. Complete the reimbursement request form.\\n2. Attach all relevant receipts.\\n3. Submit to the HR department for approval.\\n\\n**7. Review and Approval**\\n\\nHR will review submissions for compliance with this policy and will either approve or deny the\\n\\nrequest within 10 business days.\\n\\n\\n**8. Policy Amendments**\\n\\nThis policy may be amended at any time with prior notice to employees.\\n\\n\\n\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_state = State(md_text=\"\")\n",
    "\n",
    "extract_hr_policy_from_pdf(current_state, \"C:/Users/Abhishek/Downloads/task-1-dataset/HR_Policy.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e38756",
   "metadata": {},
   "source": [
    "### Extracting \n",
    "ZIP file containing one or more employee invoice PDFs.\n",
    "Employee Name: To link the invoice analysis to a specific employee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f78ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_invoices(state, zip_path):\n",
    "    \"\"\"Main function: Extract ZIP → Process PDFs → Store in state\"\"\"\n",
    "\n",
    "    # Initialize state\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        state[\"employee_invoice_data\"] = {}\n",
    "\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            # Step 1: Extract ZIP and find all PDFs\n",
    "            pdf_files = extract_zip_and_find_pdfs(zip_path, temp_dir)\n",
    "            print(f\"Found {len(pdf_files)} PDF files\")\n",
    "\n",
    "            # Step 2: Process each PDF\n",
    "            for pdf_path in pdf_files:\n",
    "                invoice_data = extract_invoice_data(pdf_path, state)\n",
    "\n",
    "                if invoice_data:\n",
    "                    employee_name = get_employee_name(invoice_data)\n",
    "\n",
    "                    # Step 3: Store in state\n",
    "                    if employee_name in state[\"employee_invoice_data\"]:\n",
    "                        state[\"employee_invoice_data\"][employee_name] += \"\\n\\n---\\n\\n\" + invoice_data\n",
    "                    else:\n",
    "                        state[\"employee_invoice_data\"][employee_name] = invoice_data\n",
    "\n",
    "            print(f\"Processed {len(state['employee_invoice_data'])} employees\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        state[\"employee_invoice_data\"][\"Error\"] = str(e)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4a1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_and_find_pdfs(zip_path, extract_to):\n",
    "    \"\"\"Extract ZIP file and return list of PDF file paths\"\"\"\n",
    "    pdf_files = []\n",
    "    \n",
    "    # Extract ZIP\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    \n",
    "    # Find all PDFs (including nested ZIPs)\n",
    "    for root, dirs, files in os.walk(extract_to):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            if file.lower().endswith('.pdf'):\n",
    "                pdf_files.append(file_path)\n",
    "            \n",
    "            elif file.lower().endswith('.zip'):\n",
    "                # Handle nested ZIP\n",
    "                nested_dir = os.path.join(root, f\"nested_{file[:-4]}\")\n",
    "                os.makedirs(nested_dir, exist_ok=True)\n",
    "                nested_pdfs = extract_zip_and_find_pdfs(file_path, nested_dir)\n",
    "                pdf_files.extend(nested_pdfs)\n",
    "    \n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95cc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_invoice_data(pdf_path, state):\n",
    "    \"\"\"Extract invoice data from PDF using text extraction or vision model\"\"\"\n",
    "    try:\n",
    "        # Try text extraction first\n",
    "        text = pymupdf4llm.to_markdown(pdf_path)\n",
    "\n",
    "        if not text or text.strip() == \"\":\n",
    "            # Use vision model if text extraction fails\n",
    "            text = extract_with_vision(pdf_path, state)\n",
    "        else:\n",
    "            # Process extracted text with LLM\n",
    "            text = process_with_llm(text, state)\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a9181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_vision(pdf_path, state):\n",
    "    \"\"\"Use vision model to extract data from PDF images\"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_text = []\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "        img_data = pix.tobytes(\"png\")\n",
    "        img_base64 = base64.b64encode(img_data).decode()\n",
    "\n",
    "        # Get the image content first, then process with full prompt\n",
    "        message = HumanMessage(content=[\n",
    "            {\"type\": \"text\", \"text\": \"Extract all text and details from this invoice image:\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"}}\n",
    "        ])\n",
    "\n",
    "        response = llm.invoke([message])\n",
    "        extracted_text = response.content\n",
    "        \n",
    "        # Now process with full prompt including status prediction\n",
    "        full_prompt = get_extraction_prompt(state)\n",
    "        final_message = HumanMessage(content=f\"{full_prompt}\\n\\nExtracted text:\\n\\n{extracted_text}\")\n",
    "        final_response = llm.invoke([final_message])\n",
    "        \n",
    "        all_text.append(final_response.content)\n",
    "\n",
    "    doc.close()\n",
    "    return \"\\n\\n\".join(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "589ad563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_llm(text, state):\n",
    "    \"\"\"Process text-extracted content with LLM for better structure\"\"\"\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "    prompt = get_extraction_prompt(state)\n",
    "    \n",
    "    message = HumanMessage(content=f\"{prompt}\\n\\nExtracted text:\\n\\n{text}\")\n",
    "    response = llm.invoke([message])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "def get_extraction_prompt(State):\n",
    "    \"\"\"Standard prompt for invoice data extraction\"\"\"\n",
    "    md_text = State.get(\"md_text\", \"\")\n",
    "    return f\"\"\"Extract invoice information and identify the EMPLOYEE NAME.\n",
    "\n",
    "EMPLOYEE NAME RULES:\n",
    "- For MEAL invoices: Look for \"Customer Name\"\n",
    "- For TRAVEL invoices: Look for \"Passenger Details\" \n",
    "- For CAB invoices: Look for \"Customer Name\"\n",
    "- If no customer/passenger name found: use \"No information about employee\"\n",
    "\n",
    "REIMBURSEMENT STATUS ANALYSIS:\n",
    "Based on the HR reimbursement policy below, analyze the invoice and determine status:\n",
    "\n",
    "**HR REIMBURSEMENT POLICY:**\n",
    "{md_text}\n",
    "\n",
    "**Reimbursement Status Categories:**\n",
    "- **Fully Reimbursed:** The entire invoice amount is reimbursable according to the HR policy\n",
    "- **Partially Reimbursed:** Only a portion of the invoice amount is reimbursable according to the HR policy\n",
    "- **Declined:** The invoice is not reimbursable according to the HR policy\n",
    "\n",
    "FORMAT:\n",
    "**EMPLOYEE NAME:** [exact name or \"No information about employee\"]\n",
    "\n",
    "**REIMBURSEMENT STATUS:** [**Fully Reimbursed** OR **Partially Reimbursed** OR **Declined**]\n",
    "\n",
    "**INVOICE DETAILS:**\n",
    "- Invoice Type: [Meal/Travel/Cab/Accomodation/Other]\n",
    "- Invoice Number: [if available]\n",
    "- Date: [date]\n",
    "- Total Amount: [amount with currency]\n",
    "- Description: [brief description]\n",
    "- Reason: What is the reason for this reimbursement?\n",
    "\n",
    "Return clean markdown format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff972178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_employee_name(invoice_text):\n",
    "    \"\"\"Extract employee name from processed invoice text\"\"\"\n",
    "    try:\n",
    "        lines = invoice_text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if '**EMPLOYEE NAME:**' in line:\n",
    "                name = line.split(':', 1)[1].strip()\n",
    "                name = name.replace('**', '').replace('*', '').strip()\n",
    "                \n",
    "                if name and name != \"No information about employee\":\n",
    "                    return name\n",
    "        \n",
    "        # Fallback: search for customer patterns\n",
    "        patterns = [\n",
    "            r'Customer Name[:\\s]+([A-Za-z\\s]+)',\n",
    "            r'Passenger[:\\s]+([A-Za-z\\s]+)',\n",
    "            r'Name[:\\s]+([A-Za-z\\s]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, invoice_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                name = matches[0].strip()\n",
    "                if name and len(name) > 1:\n",
    "                    return name\n",
    "        \n",
    "        return \"No information about employee\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing employee name: {e}\")\n",
    "        return \"No information about employee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b60fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_employee_invoices(state, employee_name):\n",
    "    \"\"\"Get all invoices for a specific employee\"\"\"\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        return \"No invoice data available\"\n",
    "    \n",
    "    # Exact match\n",
    "    if employee_name in state[\"employee_invoice_data\"]:\n",
    "        return state[\"employee_invoice_data\"][employee_name]\n",
    "    \n",
    "    # Fuzzy match\n",
    "    for emp_name in state[\"employee_invoice_data\"].keys():\n",
    "        if employee_name.lower() in emp_name.lower() or emp_name.lower() in employee_name.lower():\n",
    "            return state[\"employee_invoice_data\"][emp_name]\n",
    "    \n",
    "    return f\"No invoices found for {employee_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36073b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(state):\n",
    "    \"\"\"Get summary of all employees and their invoices with category and description\"\"\"\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        return {}\n",
    "    \n",
    "    summary = {}\n",
    "    for employee_name, invoice_data in state[\"employee_invoice_data\"].items():\n",
    "        invoice_count = invoice_data.count(\"**INVOICE DETAILS:**\")\n",
    "        amounts = re.findall(r'Total Amount[:\\s]+[₹$]\\s*([0-9,]+\\.?\\d*)', invoice_data)\n",
    "        total_amount = sum(float(amt.replace(',', '')) for amt in amounts if amt)\n",
    "        \n",
    "        # Get invoice category and description\n",
    "        category, description = get_invoice_category_and_description(invoice_data)\n",
    "        status = get_reimbursement_status(invoice_data)\n",
    "        summary[employee_name] = {\n",
    "            'invoice_count': invoice_count,\n",
    "            'invoice_mode': category,\n",
    "            'Reimbursement_Status': status,\n",
    "            'description': description\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6928e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invoice_category_and_description(invoice_data):\n",
    "    \"\"\"Extract invoice category and generate detailed description\"\"\"\n",
    "    try:\n",
    "        # Get category from invoice type\n",
    "        category_match = re.search(r'Invoice Type[:\\s]+([A-Za-z/]+)', invoice_data, re.IGNORECASE)\n",
    "        category = category_match.group(1).lower() if category_match else \"other\"\n",
    "        \n",
    "        # Normalize category\n",
    "        if 'meal' in category or 'food' in category:\n",
    "            category = 'meal'\n",
    "        elif 'travel' in category or 'ticket' in category or 'flight' in category or 'train' in category:\n",
    "            category = 'travel'\n",
    "        elif 'cab' in category or 'taxi' in category or 'uber' in category or 'ola' in category:\n",
    "            category = 'cab'\n",
    "        elif 'hotel' in category or 'house' in category or 'pg' in category or 'hostel' in category:\n",
    "            category = 'accomodation'\n",
    "        else:\n",
    "            category = 'other'\n",
    "        \n",
    "        # Generate description using LLM\n",
    "        description = generate_description_with_llm(invoice_data, category)\n",
    "        \n",
    "        return category, description\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting category: {e}\")\n",
    "        return \"other\", \"Unable to generate description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39df4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description_with_llm(invoice_data, category):\n",
    "    \"\"\"Use LLM to generate category-specific description\"\"\"\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "        \n",
    "        if category == 'travel':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT travel description (max 2 lines):\n",
    "            \n",
    "Include: Mode of travel, total cost, from which location to where, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"Flight from Delhi to Mumbai, total cost ₹5,000, Date is 12/02/22, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ₹2000 as per 5.2 Travel Expenses \" or \"Train journey from Chennai to Bangalore, total cost ₹800, Date is 12/3/23, since it is within limit as mentioned in HR Reimbursement Policy hence it is fully reimburse as per 5.2 Travel Expenses .\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'meal':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT meal description (max 2 lines):\n",
    "            \n",
    "Include: Cuisine/food name, total cost, restaurant name, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"North Indian cuisine at Punjabi Dhaba, total cost ₹450, Date is 4/2/25, within HR Policy Budget as per 5.1 Food and Beverages.\" or \"Pizza and beverages at Domino's, total cost ₹600, Date is 23/5/24, it's not with HR Reimbursement policy as given budget by HR is ₹500 but your total cost is ₹600 hence it is partially reimburse as per 5.1 Food and Beverages .\"\n",
    "\n",
    "Include: If Cuisine/food include any wine/wodka/cigrate\n",
    "Format: \"Decline!!! as wine doesn't comes under reimbursement Policy as per 5.1 Food and Beverages.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'cab':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT cab description (max 2 lines):\n",
    "            \n",
    "Include: Total cost, pickup and drop location if available, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"Cab ride from Airport to Hotel, total cost ₹350, Date of travel is 23/2/21, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse\" or \"Uber ride within city, total cost ₹120, Date of travel is 3/01/2002, its within the limit as per 5.2 Travel Expenses hence fully reimburse.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        elif category == 'accomodation':\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT cab description (max 2 lines):\n",
    "            \n",
    "Include: Total cost, hotel name if available, Date (should stricly match DD/MM/YYYY format), reason of given reimbursement\n",
    "Format: \"You stayed in hotel for 2 days, total cost ₹350, Date of travel is 23/2/21, it's more than HR Reimbursement Policy as per 5.3 Accommodation hence partially reimburse\" or \"You stayed in PG, total cost ₹120, Date of travel is 3/01/2002, its within the limit as per 5.3 Accommodation hence fully reimburse.\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"\n",
    "        else:\n",
    "            prompt = \"\"\"Based on the following invoice data, provide a SHORT description (max 2 lines):\n",
    "            \n",
    "Include: Service type, total cost,Date (should stricly match DD/MM/YYYY format), brief details\n",
    "Format: \"Service description with cost\"\n",
    "\n",
    "Invoice data:\n",
    "\"\"\"\n",
    "        \n",
    "        message = HumanMessage(content=prompt + invoice_data)\n",
    "        response = llm.invoke([message])\n",
    "        \n",
    "        # Clean up the response\n",
    "        description = response.content.strip()\n",
    "        # Remove quotes if present\n",
    "        if description.startswith('\"') and description.endswith('\"'):\n",
    "            description = description[1:-1]\n",
    "        \n",
    "        return description\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description: {e}\")\n",
    "        return f\"Invoice total with basic details (Error: {str(e)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f569b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reimbursement_status(invoice_text):\n",
    "    \"\"\"Extract reimbursement status from processed invoice text\"\"\"\n",
    "    try:\n",
    "        lines = invoice_text.split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            if '**REIMBURSEMENT STATUS:**' in line:\n",
    "                status = line.split(':', 1)[1].strip()\n",
    "                status = status.replace('**', '').replace('*', '').strip()\n",
    "                \n",
    "                if status:\n",
    "                    return status\n",
    "        \n",
    "        # Fallback: search for status patterns\n",
    "        patterns = [\n",
    "            r'Status[:\\s]+([A-Za-z\\s*]+)',\n",
    "            r'Reimbursement[:\\s]+([A-Za-z\\s*]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            matches = re.findall(pattern, invoice_text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                status = matches[0].strip()\n",
    "                if status and len(status) > 1:\n",
    "                    return status\n",
    "        \n",
    "        return \"**Pending Review**\"  # Default status\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing reimbursement status: {e}\")\n",
    "        return \"**Pending Review**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09dd3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "import pymupdf4llm\n",
    "import fitz\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1ab045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HR POLICY EXTRACTION DEBUG ===\n",
      "HR Policy extracted: 2416 characters\n",
      "HR Policy preview: # **Company Name: IAI Solution** **Policy Title: Employee Reimbursement Policy** **Version: 1.0**\n",
      "\n",
      "**1. Purpose**\n",
      "\n",
      "The purpose of this policy is to outline the guidelines and procedures for the reimbu...\n",
      "==================================================\n",
      "Found 6 PDF files\n",
      "Processed 6 employees\n",
      "Summary with categories and descriptions:\n",
      "\n",
      "Rekha:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ₹167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Seema:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ₹141, Date of travel is 19/09/2024, it's within the company's allowance limit of ₹150 hence fully reimburse.\n",
      "  Reimbursement Status: Fully Reimbursed\n",
      "\n",
      "Hardik:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: Indian cuisine at Restaurant name not specified, total cost ₹607.70, Date is 03/12/2024, it's not fully within HR Reimbursement policy as given budget by HR is ₹200 but your total cost is ₹607.70 hence it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Shivam M:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: South Indian Mini Meals and Chapati at Udapi Hotel, total cost ₹374.00, Date is 13/12/2024, meal reimbursement for work-related purposes, and it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Sushma:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Bangalore to Surat, total cost ₹7377, Date is 25/07/2024, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ₹2,000 per trip.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Rani:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Chennai to Surat, total cost ₹9899, Date is 25/07/2024, reason of partially reimbursement is that the total fare of ₹9899 exceeds the HR policy limit of ₹2,000 for travel reimbursements per trip, making only a portion eligible for reimbursement.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "==================================================\n",
      "=== STATE CONTENTS ===\n",
      "Available keys: ['md_text', 'employee_invoice_data', 'extract_invoice_data']\n",
      "\n",
      "=== extract_invoice_data ===\n",
      "Type: <class 'dict'>\n",
      "Number of employees: 6\n",
      "\n",
      "Rekha:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ₹167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Seema:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: cab\n",
      "  Description: Daily office cab ride, total cost ₹141, Date of travel is 19/09/2024, it's within the company's allowance limit of ₹150 hence fully reimburse.\n",
      "  Reimbursement Status: Fully Reimbursed\n",
      "\n",
      "Hardik:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: Indian cuisine at Restaurant name not specified, total cost ₹607.70, Date is 03/12/2024, it's not fully within HR Reimbursement policy as given budget by HR is ₹200 but your total cost is ₹607.70 hence it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Shivam M:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: meal\n",
      "  Description: South Indian Mini Meals and Chapati at Udapi Hotel, total cost ₹374.00, Date is 13/12/2024, meal reimbursement for work-related purposes, and it is partially reimbursed as per 5.1 Food and Beverages.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Sushma:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Bangalore to Surat, total cost ₹7377, Date is 25/07/2024, reason of partially reimbursement is that for traveling cost as per HR Policy we can reimburse only ₹2,000 per trip.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "Rani:\n",
      "  Invoice Count: 1\n",
      "  Invoice Mode: travel\n",
      "  Description: Flight from Chennai to Surat, total cost ₹9899, Date is 25/07/2024, reason of partially reimbursement is that the total fare of ₹9899 exceeds the HR policy limit of ₹2,000 for travel reimbursements per trip, making only a portion eligible for reimbursement.\n",
      "  Reimbursement Status: Partially Reimbursed\n",
      "\n",
      "=== employee_invoice_data (raw) ===\n",
      "Number of employees: 6\n",
      "- Rekha\n",
      "- Seema\n",
      "- Hardik\n",
      "- Shivam M\n",
      "- Sushma\n",
      "- Rani\n",
      "\n",
      "==================================================\n",
      "Sample employee data for 'Rekha':\n",
      "{'invoice_count': 1, 'invoice_mode': 'cab', 'Reimbursement_Status': 'Partially Reimbursed', 'description': \"Daily office cab ride, total cost ₹167, Date of travel is 17/09/2024, it's more than HR Reimbursement Policy as per 5.2 Travel Expenses hence partially reimburse.\"}\n"
     ]
    }
   ],
   "source": [
    "# Modified example_usage function to accept state as parameter\n",
    "def example_usage(state):\n",
    "    \"\"\"Example of how to use the code - now accepts state as parameter\"\"\"\n",
    "\n",
    "    state = {\"md_text\": \"\", \"employee_invoice_data\": {}}\n",
    "    state = extract_hr_policy_from_pdf(state, \"C:/Users/Abhishek/Downloads/task-1-dataset/HR_Policy.pdf\")\n",
    "\n",
    "    # Debug: Check if HR policy was extracted\n",
    "    print(\"=== HR POLICY EXTRACTION DEBUG ===\")\n",
    "    print(f\"HR Policy extracted: {len(state.get('md_text', ''))} characters\")\n",
    "    if state.get('md_text'):\n",
    "        print(f\"HR Policy preview: {state['md_text'][:200]}...\")\n",
    "    else:\n",
    "        print(\"WARNING: No HR policy extracted!\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Step 1: Initialize state if needed (don't create new state)\n",
    "    if \"employee_invoice_data\" not in state:\n",
    "        state[\"employee_invoice_data\"] = {}\n",
    "\n",
    "    # Step 2: Process ZIP file\n",
    "    zip_path = \"C:/Users/Abhishek/Downloads/dataset.zip\"\n",
    "    state = process_invoices(state, zip_path)\n",
    "\n",
    "    # Step 3: Get results with category and description\n",
    "    summary = get_summary(state)\n",
    "    \n",
    "    # Step 4: Store summary in state[\"extract_invoice_data\"] (as you wanted)\n",
    "    state[\"extract_invoice_data\"] = summary\n",
    "    \n",
    "    print(\"Summary with categories and descriptions:\")\n",
    "    for employee, details in summary.items():\n",
    "        print(f\"\\n{employee}:\")\n",
    "        print(f\"  Invoice Count: {details['invoice_count']}\")\n",
    "        print(f\"  Invoice Mode: {details['invoice_mode']}\")\n",
    "        print(f\"  Description: {details['description']}\")\n",
    "        print(f\"  Reimbursement Status: {details['Reimbursement_Status']}\")\n",
    "\n",
    "    return state\n",
    "\n",
    "# Alternative: If you want to check what's stored\n",
    "def check_state_contents(state):\n",
    "    \"\"\"Helper function to check what's stored in state\"\"\"\n",
    "    print(\"=== STATE CONTENTS ===\")\n",
    "    print(f\"Available keys: {list(state.keys())}\")\n",
    "    \n",
    "    # Check extract_invoice_data\n",
    "    if \"extract_invoice_data\" in state:\n",
    "        print(f\"\\n=== extract_invoice_data ===\")\n",
    "        print(f\"Type: {type(state['extract_invoice_data'])}\")\n",
    "        print(f\"Number of employees: {len(state['extract_invoice_data'])}\")\n",
    "        \n",
    "        for employee, details in state[\"extract_invoice_data\"].items():\n",
    "            print(f\"\\n{employee}:\")\n",
    "            print(f\"  Invoice Count: {details['invoice_count']}\")\n",
    "            print(f\"  Invoice Mode: {details['invoice_mode']}\")\n",
    "            print(f\"  Description: {details['description']}\")\n",
    "            print(f\"  Reimbursement Status: {details['Reimbursement_Status']}\") \n",
    "    \n",
    "    # Check raw employee_invoice_data\n",
    "    if \"employee_invoice_data\" in state:\n",
    "        print(f\"\\n=== employee_invoice_data (raw) ===\")\n",
    "        print(f\"Number of employees: {len(state['employee_invoice_data'])}\")\n",
    "        for emp_name in state[\"employee_invoice_data\"].keys():\n",
    "            print(f\"- {emp_name}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    state = {}\n",
    "    \n",
    "    # Process invoices and get results\n",
    "    state = example_usage(state)\n",
    "    \n",
    "    # Optional: Check what's stored\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    check_state_contents(state)\n",
    "    \n",
    "    # Optional: Access specific employee data\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    if \"extract_invoice_data\" in state:\n",
    "        employee_name = list(state[\"extract_invoice_data\"].keys())[0]  # Get first employee\n",
    "        print(f\"Sample employee data for '{employee_name}':\")\n",
    "        print(state[\"extract_invoice_data\"][employee_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4e528",
   "metadata": {},
   "source": [
    "### Let's store employee name and its detail in Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c194467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from typing import Dict, List, Optional, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8077f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"employee-database\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063068c",
   "metadata": {},
   "source": [
    "Since we need to add date in meta data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1917b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_from_description(description: str) -> Optional[str]:\n",
    "    \"\"\"Extract date from description using regex.\"\"\"\n",
    "    if not description:\n",
    "        return None\n",
    "    \n",
    "    # Simple regex for DD/MM/YYYY format\n",
    "    date_pattern = r'\\b(\\d{1,2})/(\\d{1,2})/(\\d{4})\\b'\n",
    "    match = re.search(date_pattern, description)\n",
    "    \n",
    "    if match:\n",
    "        day, month, year = match.groups()\n",
    "        return f\"{day.zfill(2)}/{month.zfill(2)}/{year}\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194dd3e",
   "metadata": {},
   "source": [
    "Our main logic here to push employee 1 along with its all relavent detail as one chunk along with employee name and date as meta data and later on we will perform Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76e67f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_employees_to_pinecone(employee_invoice_data: Dict[str, Dict[str, str]]):\n",
    "    \"\"\"\n",
    "    Process employee data and add to Pinecone - Simple approach like your example.\n",
    "    \"\"\"\n",
    "    # Initialize embeddings and Pinecone\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Setup Pinecone index (create if not exists)\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    \n",
    "    # Create index if it doesn't exist\n",
    "    existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "\n",
    "    if INDEX_NAME in existing_indexes:\n",
    "        print(f\"🗑️  Deleting existing index: {INDEX_NAME}\")\n",
    "        pc.delete_index(INDEX_NAME)\n",
    "        \n",
    "        # Wait for deletion to complete (important!)\n",
    "        import time\n",
    "        print(\"⏳ Waiting for index deletion to complete...\")\n",
    "        while INDEX_NAME in [index.name for index in pc.list_indexes()]:\n",
    "            time.sleep(1)\n",
    "        print(\"✅ Index deletion completed\")\n",
    "\n",
    "    \n",
    "    print(f\"🆕 Creating fresh index: {INDEX_NAME}\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    \n",
    "    # Wait for index to be ready\n",
    "    print(\"⏳ Waiting for index to be ready...\")\n",
    "    while not pc.Index(INDEX_NAME).describe_index_stats():\n",
    "        time.sleep(1)\n",
    "    print(\"✅ Index is ready\")\n",
    "\n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Process each employee - similar to your page_info loop\n",
    "    all_chunks = []\n",
    "    \n",
    "    for employee_name, employee_data in employee_invoice_data.items():\n",
    "        # Create text content\n",
    "        text = f\"\"\"\n",
    "        Employee Name: {employee_name}\n",
    "        Invoice Count: {employee_data.get('invoice_count', 0)}\n",
    "        Invoice Mode: {employee_data.get('invoice_mode', 'N/A')}\n",
    "        Reimbursement Status: {employee_data.get('Reimbursement_Status', 'N/A')}\n",
    "        Description: {employee_data.get('description', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract date from description\n",
    "        extracted_date = extract_date_from_description(employee_data.get('description', ''))\n",
    "        \n",
    "        # Create document - similar to your Document creation\n",
    "        doc = Document(\n",
    "            page_content=text.strip(),\n",
    "            metadata={\n",
    "                \"employee_name\": employee_name,\n",
    "                \"date\": extracted_date,\n",
    "                \"document_type\": \"employee_record\",\n",
    "                \"text\": text.strip()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        all_chunks.append(doc)\n",
    "    \n",
    "    # Add all documents to Pinecone\n",
    "    vector_store.add_documents(all_chunks)\n",
    "    time.sleep(1)\n",
    "    print(f\"✅ Successfully added {len(all_chunks)} employee records to Pinecone\")\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Pinecone Data Verification...\n",
      "\n",
      "==================================================\n",
      "STEP 1: Index Stats & Employee Search\n",
      "==================================================\n",
      "📊 Index Stats:\n",
      "   Total Vectors: 3\n",
      "   Dimension: 384\n",
      "   Index Fullness: 0.0\n",
      "\n",
      "🔍 Searching for: Sarah\n",
      "✅ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2105\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ₹8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Searching for: John\n",
      "✅ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: John\n",
      "   Date: 18/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2822\n",
      "   Content:\n",
      "   Employee Name: John\n",
      "        Invoice Count: 2\n",
      "        Invoice Mode: food\n",
      "        Reimbursement Status: Fully Reimbursed\n",
      "        Description: Team lunch expense, total cost ₹450, Date of travel is 18/09/2024, within policy limits.\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Searching for: Rekha\n",
      "✅ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.1962\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ₹167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Searching for: Mike\n",
      "❌ No results found\n",
      "\n",
      "==================================================\n",
      "STEP 2: All Documents in Index\n",
      "==================================================\n",
      "🔍 ALL DOCUMENTS IN INDEX:\n",
      "✅ Found 3 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: John\n",
      "   Date: 18/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.3031\n",
      "   Content:\n",
      "   Employee Name: John\n",
      "        Invoice Count: 2\n",
      "        Invoice Mode: food\n",
      "        Reimbursement Status: Fully Reimbursed\n",
      "        Description: Team lunch expense, total cost ₹450, Date of travel is 18/09/2024, within policy limits.\n",
      "------------------------------------------------------------\n",
      "\n",
      "📄 RESULT 2:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2404\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ₹8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n",
      "\n",
      "📄 RESULT 3:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2255\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ₹167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "👥 Unique Employee Names Found: ['Sarah', 'John', 'Rekha']\n",
      "\n",
      "==================================================\n",
      "STEP 3: Specific Employee Searches\n",
      "==================================================\n",
      "🔍 Testing with 'Rekha' (from your example):\n",
      "✅ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: Rekha\n",
      "   Date: 17/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.1962\n",
      "   Content:\n",
      "   Employee Name: Rekha\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: cab\n",
      "        Reimbursement Status: Partially Reimbursed\n",
      "        Description: Cab ride within city, total cost ₹167, Date of travel is 17/09/2024, it's more than the reimbursement policy hence partially reimburse.\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔍 Testing with 'Sarah':\n",
      "✅ Found 1 results:\n",
      "================================================================================\n",
      "\n",
      "📄 RESULT 1:\n",
      "   Employee Name: Sarah\n",
      "   Date: 20/09/2024\n",
      "   Document Type: employee_record\n",
      "   Similarity Score: 0.2105\n",
      "   Content:\n",
      "   Employee Name: Sarah\n",
      "        Invoice Count: 1\n",
      "        Invoice Mode: travel\n",
      "        Reimbursement Status: Pending\n",
      "        Description: Flight booking for business trip, total cost ₹8500, Date of travel is 20/09/2024, awaiting approval.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def search_by_employee_name(employee_name: str, top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Search for documents by employee name using metadata filtering\n",
    "    \n",
    "    Args:\n",
    "        employee_name: Name of employee to search for\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of documents with metadata\n",
    "    \"\"\"\n",
    "    # Initialize embeddings (same as used during indexing)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Initialize vector store\n",
    "    vector_store = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    # Create metadata filter for employee name\n",
    "    metadata_filter = {\"employee_name\": employee_name}\n",
    "    \n",
    "    # Perform search with metadata filter\n",
    "    # Using a generic query since we're mainly filtering by metadata\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query=\"employee record\",\n",
    "        k=top_k,\n",
    "        filter=metadata_filter\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_search_results(results):\n",
    "    \"\"\"\n",
    "    Print search results in a readable format\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"❌ No results found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Found {len(results)} results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n📄 RESULT {i}:\")\n",
    "        print(f\"   Employee Name: {doc.metadata.get('employee_name', 'N/A')}\")\n",
    "        print(f\"   Date: {doc.metadata.get('date', 'N/A')}\")\n",
    "        print(f\"   Document Type: {doc.metadata.get('document_type', 'N/A')}\")\n",
    "        print(f\"   Similarity Score: {score:.4f}\")\n",
    "        print(f\"   Content:\")\n",
    "        print(f\"   {doc.page_content}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "def verify_pinecone_data():\n",
    "    \"\"\"\n",
    "    Verify what data is stored in Pinecone\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize Pinecone client\n",
    "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        index = pc.Index(INDEX_NAME)\n",
    "        \n",
    "        # Get index stats\n",
    "        stats = index.describe_index_stats()\n",
    "        print(f\"📊 Index Stats:\")\n",
    "        print(f\"   Total Vectors: {stats.total_vector_count}\")\n",
    "        print(f\"   Dimension: {stats.dimension}\")\n",
    "        print(f\"   Index Fullness: {stats.index_fullness}\")\n",
    "        \n",
    "        # Test with different employee names\n",
    "        test_employees = [\"Sarah\", \"John\", \"Rekha\", \"Mike\"]\n",
    "        \n",
    "        for employee in test_employees:\n",
    "            print(f\"\\n🔍 Searching for: {employee}\")\n",
    "            results = search_by_employee_name(employee)\n",
    "            print_search_results(results)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "\n",
    "def search_all_employees():\n",
    "    \"\"\"\n",
    "    Get all documents without any filter to see what's in the index\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize embeddings and vector store\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        vector_store = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings\n",
    "        )\n",
    "        \n",
    "        # Search without any filter to get all documents\n",
    "        results = vector_store.similarity_search_with_score(\n",
    "            query=\"employee\",\n",
    "            k=20  # Get more results to see all employees\n",
    "        )\n",
    "        \n",
    "        print(f\"🔍 ALL DOCUMENTS IN INDEX:\")\n",
    "        print_search_results(results)\n",
    "        \n",
    "        # Extract unique employee names\n",
    "        employee_names = set()\n",
    "        for doc, score in results:\n",
    "            name = doc.metadata.get('employee_name')\n",
    "            if name:\n",
    "                employee_names.add(name)\n",
    "        \n",
    "        print(f\"\\n👥 Unique Employee Names Found: {list(employee_names)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error searching all employees: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be715eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "def answer_query_for_employee(employee_name: str, query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Answer a user query for a specific employee using Pinecone context and Gemini LLM.\n",
    "\n",
    "    Args:\n",
    "        employee_name: The name of the employee to search for\n",
    "        query: The user's question (e.g. reimbursement status)\n",
    "        top_k: Number of Pinecone results to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Answer string from Gemini\n",
    "    \"\"\"\n",
    "    # Step 1: Get relevant documents for the employee\n",
    "    results = search_by_employee_name(employee_name, top_k=top_k)\n",
    "\n",
    "    if not results:\n",
    "        return f\"❌ No data found for employee: {employee_name}\"\n",
    "\n",
    "    # Step 2: Concatenate all context from Pinecone\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc, _ in results])\n",
    "\n",
    "    # Step 3: Define a prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "You are an HR assistant AI. Use the following employee information to answer the user's question.\n",
    "\n",
    "Employee Data:\n",
    "------------------\n",
    "{context}\n",
    "\n",
    "User Question:\n",
    "------------------\n",
    "{question}\n",
    "\n",
    "Give a concise, helpful, and context-grounded answer.\n",
    "\"\"\",\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    # Step 4: Create LLM Chain\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "    # Step 5: Run the chain\n",
    "    response = chain.run({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9651c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Answer:\n",
      "John has 2 food-related expenses, totaling ₹450 for a team lunch on 18/09/2024. These expenses have been fully reimbursed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    emp_name = \"John\"\n",
    "    user_query = \"What are his expenses?\"\n",
    "\n",
    "    answer = answer_query_for_employee(emp_name, user_query)\n",
    "    print(f\"\\n🤖 Answer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2285f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 Answer:\n",
      "Your cab ride cost ₹167, which is more than the amount allowed by the company's reimbursement policy. Therefore, you were partially reimbursed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    emp_name = \"Rekha\"\n",
    "    user_query = \"Why I had been partially reimbersued?\"\n",
    "\n",
    "    answer = answer_query_for_employee(emp_name, user_query)\n",
    "    print(f\"\\n🤖 Answer:\\n{answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
